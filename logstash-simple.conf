input {
    kafka {
        host => "10.0.227.26"
        port => 9092
        topic => "log_rails"
        message_format => "plain"
        type => "plain"
    }
}
filter {
  grok {
    break_on_match => true
    # [ec2-....][23997]|[RAILS][2013 12 25 18:18:21.459 -0700][INFO]: GET 200 /analyze 425.79
    #Rails controller (with optional exception logging)
    pattern => "\[%{HOSTNAME:src}\]\[%{NUMBER:pid}\]\|\[(?<application>RAILS)\]\[%{DATA:datetime}\]\[%{WORD:level}\]: %{WORD:method} %{NUMBER:status} %{DATA:path} (?<duration>\d*(?:\.\d+)?)( EXCEPTION: %{DATA:exception}$)?"

    #Rails Exceptions
    pattern => "\[%{HOSTNAME:src}\]\[%{NUMBER:pid}\]\|\[(?<application>RAILS)\]\[%{DATA:datetime}\]\[(?<level>EXCEPTION)\]: msg:%{DATA:errormsg} - inspect:%{DATA:errorobject} - backtrace:%{DATA:backtrace}$"

    #Rails catch-all
    # Params and Timings for manual analysis or map-reduce / additional parsing
    pattern => "\[%{HOSTNAME:src}\]\[%{NUMBER:pid}\]\|\[(?<application>RAILS)\]\[%{DATA:datetime}\]\[%{WORD:level}\]: %{DATA:data}$"



    #Database queries
    pattern => "\[%{HOSTNAME:src}\]\[%{NUMBER:pid}\]\|\[(?<application>ACTIVERECORD|MONGO)\]\[%{DATA:datetime}\]\[%{WORD:level}\]:%{DATA:query}$"


  }
}
output { 
    stdout { debug => true debug_format => "json"}
    elasticsearch { embedded => false }
} 
